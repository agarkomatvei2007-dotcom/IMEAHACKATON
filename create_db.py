"""
Ğ¡ĞºÑ€Ğ¸Ğ¿Ñ‚ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğ¹ Ğ±Ğ°Ğ·Ñ‹
"""
from pathlib import Path
from src.embedder import Embedder
from src.vector_store import VectorStore
from config import DOCS_DIR, CHUNK_SIZE, CHUNK_OVERLAP
import re


def load_document(filepath: Path) -> str:
    """Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚ Ğ¸Ğ· Ñ„Ğ°Ğ¹Ğ»Ğ°"""
    with open(filepath, 'r', encoding='utf-8') as f:
        return f.read()


def chunk_text(text: str, chunk_size: int = CHUNK_SIZE, overlap: int = CHUNK_OVERLAP) -> list:
    """Ğ Ğ°Ğ·Ğ±Ğ¸Ñ‚ÑŒ Ñ‚ĞµĞºÑÑ‚ Ğ½Ğ° Ñ‡Ğ°Ğ½ĞºĞ¸"""
    # Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ¿Ğ¾ Ğ¿Ğ°Ñ€Ğ°Ğ³Ñ€Ğ°Ñ„Ğ°Ğ¼
    paragraphs = text.split('\n\n')
    
    chunks = []
    current_chunk = ""
    
    for para in paragraphs:
        para = para.strip()
        if not para:
            continue
        
        # Ğ•ÑĞ»Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ³Ñ€Ğ°Ñ„ ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ¹, Ñ€Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ¿Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸ÑĞ¼
        if len(para) > chunk_size:
            sentences = re.split(r'[.!?]\s+', para)
            for sentence in sentences:
                if len(current_chunk) + len(sentence) < chunk_size:
                    current_chunk += sentence + ". "
                else:
                    if current_chunk:
                        chunks.append(current_chunk.strip())
                    current_chunk = sentence + ". "
        else:
            if len(current_chunk) + len(para) < chunk_size:
                current_chunk += para + "\n\n"
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = para + "\n\n"
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks


def main():
    print("ğŸš€ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğ¹ Ğ±Ğ°Ğ·Ñ‹ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹\n")
    
    # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ²ÑĞµ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹
    print("ğŸ“‚ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²...")
    docs = list(DOCS_DIR.glob("*.md"))
    
    if not docs:
        print("âŒ ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ²", DOCS_DIR)
        return
    
    print(f"âœ… ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ {len(docs)} Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²\n")
    
    all_chunks = []
    all_metadatas = []
    
    for doc in docs:
        print(f"ğŸ“„ ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°: {doc.name}")
        text = load_document(doc)
        chunks = chunk_text(text)
        
        for chunk in chunks:
            all_chunks.append(chunk)
            all_metadatas.append({
                'source': doc.name,
                'filename': doc.stem
            })
        
        print(f"   â””â”€ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¾ {len(chunks)} Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²")
    
    print(f"\nğŸ“Š Ğ’ÑĞµĞ³Ğ¾ Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²: {len(all_chunks)}\n")
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¸
    print("ğŸ”„ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ²...")
    embedder = Embedder()
    embeddings = embedder.embed_batch(all_chunks)
    print(f"âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¾ {len(embeddings)} ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ²\n")
    
    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ² Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½ÑƒÑ Ğ±Ğ°Ğ·Ñƒ
    print("ğŸ’¾ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ² Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½ÑƒÑ Ğ±Ğ°Ğ·Ñƒ...")
    store = VectorStore()
    store.create_collection()
    store.add_documents(all_chunks, embeddings, all_metadatas)
    
    print("\nâœ… Ğ’ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ°Ñ Ğ±Ğ°Ğ·Ğ° Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ°!")
    print("Ğ¢ĞµĞ¿ĞµÑ€ÑŒ Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸: python app.py\n")


if __name__ == "__main__":
    main()
